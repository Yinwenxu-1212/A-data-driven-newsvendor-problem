\documentclass[a4paper,12pt]{article}

% 宏包设置
\usepackage{amsmath, amssymb, amsfonts} % 数学公式支持
\usepackage{geometry} % 页面布局
\usepackage{graphicx} % 图片插入
\usepackage{booktabs} % 表格美化
\usepackage{hyperref} % 超链接
\usepackage{enumitem} % 列表格式
\usepackage{float}
\usepackage[UTF8]{ctex}

% 页面边距
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

% 标题信息
\title{\textbf{From Data to Decision: A Data-Driven Approach to the Newsvendor Problem}\\
\large —— 课程文献阅读与复现报告}
\author{汇报人：[您的姓名] \\ 课程：高级应用统计}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
本文深度解读了 Huber 等人发表于 \textit{EJOR} (2019) 的论文。文章针对报童问题中需求分布未知的核心挑战，提出了基于大数据的三层决策框架。我们详细阐述了从需求预测到库存优化的统计方法论，并基于 Kaggle 的 French Bakery 数据集进行了实证复现，验证了非参数方法在库存决策中的有效性。
\end{abstract}

% 第一部分：基本研究问题
\section{The Basic Research Problem}

\subsection{商业背景与权衡}
本文聚焦于零售管理中经典的\textbf{报童问题}。零售商（如连锁面包店）需在销售季节前决定易腐产品的订货量 $q$。核心权衡在于最小化期望总成本：
\begin{equation}
    \min_{q} \mathbb{E}[C(q, D)] = \mathbb{E} [c_u (D - q)^+ + c_o (q - D)^+]
\end{equation}
其中 $D$ 为随机需求，$c_u$ 为缺货成本，$c_o$ 为超储成本。

\subsection{统计学挑战}
在理论最优解中，订货量 $q^*$ 取决于需求累积分布函数 $F$ 的分位数：$q^* = F^{-1}(\frac{c_u}{c_u + c_o})$。
然而，现实中的\textbf{根本难题}在于：
\begin{itemize}
    \item \textbf{分布未知}：真实的需求分布 $F$ 往往无法获知，且可能随时间变化。
    \item \textbf{特征利用不足}：传统方法往往忽略了天气、节假日、促销等外部特征向量 $X$ 对需求分布的影响。
\end{itemize}
因此，本文的研究问题是：\textbf{如何利用历史数据 $(D_t, X_t)$，在不预设分布形式的前提下，构建数据驱动的模型以实现成本最小化？}

% 第二部分：思想与方法论
\section{The Idea and Methodology}

本文提出了一个\textbf{三层递进的数据驱动框架}，涵盖了从参数估计到非参数优化的完整路径。

\subsection{Level 1: Demand Estimation (点预测)}
利用统计学习方法估计给定特征 $x$ 下的需求期望 $\hat{y}(x) = \mathbb{E}[d|x]$。
\begin{itemize}
    \item \textbf{传统方法}：ARIMA, ETS (指数平滑)。
    \item \textbf{机器学习}：文章构建了单隐层多层感知机。
    \begin{equation}
        \hat{y}(x) = f(W^{(2)} \sigma(W^{(1)}x + b^{(1)}) + b^{(2)})
    \end{equation}
    通过引入特征工程（如滞后销量 $Lag\_1, Lag\_7$ 和日历特征），捕捉非线性模式。
\end{itemize}

\subsection{Level 2: 库存优化}
基于预测结果 $\hat{y}$ 和预测误差 $\epsilon = d - \hat{y}$ 进行决策。
\begin{itemize}
    \item \textbf{参数化方法}：假设误差服从正态分布 $\epsilon \sim \mathcal{N}(0, \hat{\sigma}^2)$。
    $$q(x) = \hat{y}(x) + \Phi^{-1}(\text{target ratio}) \cdot \hat{\sigma}$$
    \item \textbf{非参数方法}：\textbf{样本均值逼近}。不假设分布，直接使用历史误差样本的经验分布寻找分位数。
    \textbf{优势}：避免了模型误设风险，更具鲁棒性。
\end{itemize}

\subsection{Level 3: 集成优化}
跳过点预测，直接建立特征 $x$ 到最优订货量 $q^*$ 的映射。这等价于\textbf{分位数回归}。
我们将报童损失函数直接作为神经网络的训练目标：
\begin{equation}
    \mathcal{L} = \frac{1}{n} \sum_{i=1}^{n} \left[ c_u (d_i - q(x_i))^+ + c_o (q(x_i) - d_i)^+ \right]
\end{equation}
该方法能自动适应\textbf{异方差性}（即需求的波动随特征变化）。

% 第三部分：结果（包含论文结果与复现结果）
\section{数据来源及处理}
\subsection{原论文数据处理}
原研究采用了德国某大型连锁面包店的销售数据，涵盖 5 家门店的 11 种核心产品，时间跨度为 88 周。针对零售数据中普遍存在的\textbf{需求截断}问题——即因库存耗尽导致观测到的销量低于真实需求，原作者创新性地利用日内销售模式对缺货时段进行了插值还原，从而获得了对真实历史需求的估计。此外，为了捕捉复杂的消费行为模式，原研究构建了包含天气（温度、云层）、地理位置（学校、商圈）及详细日历特征的丰富外生变量集。

\subsection{复现数据构建与预处理}
鉴于原研究所用的企业私有数据未公开，本研究选取了业务模式高度相似的 \textbf{Kaggle "French Bakery Daily Sales"} 公开数据集作为替代。为在现有数据条件下最大程度复现论文的方法论，我们执行了系统性的数据处理流程。

首先进行\textbf{数据重构与清洗}。原始数据为交易级记录，我们将其聚合至\textbf{日粒度}，按 \texttt{date} 和 \texttt{article} 汇总销量与收入。受限于缺乏日内库存记录，本复现采用经典假设，即观测销量近似于真实需求（销量 $\approx$ 需求），并对非营业日进行了补零处理。在此基础上，建立了严格的数据质量控制规则：对价格字段进行标准化解析（处理欧元符号与逗号小数），并剔除 \texttt{sales>0} 但价格缺失或非正数的异常记录，以确保数据的准确性。

随后进行\textbf{样本筛选与特征工程}。为提升模型的代表性并减少稀疏噪音，我们依据累计销量筛选了 \textbf{前 10 核心产品}，剔除长尾低频商品。为了模拟原论文的特征体系，本研究构建了高维特征空间，具体涵盖：(1) \textbf{日历特征}，包括 \texttt{weekday}, \texttt{month} 及基于法国法定节假日库生成的 \texttt{is\_public\_holiday}；(2) \textbf{时序特征}，构建 \texttt{lag\_1}（短期依赖）和 \texttt{lag\_7}（周度周期性）以捕捉自相关性。最后，数据集严格按时间序列顺序划分为训练集与测试集（按 80/20 划分），以避免数据泄漏。

\subsection{论文原实证结果}
基于德国某大型连锁面包店 88 周的真实运营数据（涵盖 5 家门店与 11 个 SKU），Huber 等人 (2019) 进行了系统的实证评估。实验采用滚动窗口机制进行严格的样本外测试，旨在从数据规模与特征组合两个维度，全面评估不同决策模型的绩效表现。

\subsubsection{数据特征与实验设置}
针对零售数据中普遍存在的需求删失问题，研究采用了日内销售模式法对历史缺货数据进行了插值还原，从而构建了无偏的需求估计基础。在此基础上，实验设计了从 0.1 到 1.0 不同比例的训练集规模，以量化探究模型性能对数据丰富度的依赖关系，并验证各模型在不同数据环境下的稳健性。

\subsubsection{Level 1: 点预测精度分析}
在需求估计层面，研究对比了以指数平滑和 ARIMA 为代表的传统时间序列方法与以多层感知机和梯度提升树为代表的机器学习方法。如原文 \textbf{Table 3}（图 \ref{fig:paper_table3}）所示，当机器学习模型仅基于单变量时间序列进行独立训练时，其相较于传统方法的优势并不显著。

然而，当采用跨序列池化训练策略并引入高维外生特征时，机器学习模型展现出显著的性能优势。具体而言，该模型能够有效捕捉周度季节性与天气因素之间的非线性交互效应，从而大幅降低均方根误差。图 \ref{fig:paper_table3} 展示了各模型精度的具体对比，结果显示跨序列池化训练的机器学习方法在各项误差指标上均显著优于传统单变量方法。

\begin{figure}[htbp]
    \centering
    \IfFileExists{table3.png}{\includegraphics[width=0.95\textwidth]{table3.png}}{\fbox{Table 3 图缺失}}
    \caption{原文 Table 3：不同预测方法的点预测精度对比}
    \label{fig:paper_table3}
\end{figure}

\subsubsection{Level 2: 库存绩效与尾部风险}
在将预测结果转化为库存决策的过程中，研究揭示了预测精度与最终运营成本之间存在显著的正相关性，且不同优化方法的表现呈现出明显的非对称效应。

如原文 \textbf{Table 4}（图 \ref{fig:paper_table4}）所示，在目标服务水平不高于 0.9 的区间内，非参数的样本均值逼近方法普遍优于参数化的正态分布假设。这表明 SAA 方法能够更有效地利用残差分布信息，克服真实需求分布的有偏性。然而，当服务水平提升至 0.95 时，受限于尾部样本的稀疏性，SAA 方法的估计方差显著增大；此时，正态分布假设凭借其参数化的正则特性，反而能提供更为稳定的成本控制表现。图 \ref{fig:paper_table4} 清晰地展示了 SAA 方法在中低服务水平区间具有更低的相对成本。

\begin{figure}[htbp]
    \centering
    \IfFileExists{table4.png}{\includegraphics[width=0.95\textwidth]{table4.png}}{\fbox{Table 4 图缺失}}
    \caption{原文 Table 4：不同目标服务水平下的平均库存成本增加比例（相对于最佳方法）}
    \label{fig:paper_table4}
\end{figure}

\subsubsection{Level 3 与样本量敏感性分析}
针对端到端的集成优化及样本量的边际效应，原文 \textbf{Figure 5}（图 \ref{fig:paper_fig5}）提供了直观的趋势分析。研究发现，基于分位数回归的集成优化策略仅在低服务水平且数据量极其充足的条件下才具有竞争力；在数据稀疏区域，其泛化能力不如“预测加优化”的分离式策略。

此外，样本量敏感性分析表明，机器学习模型是唯一随着样本量增加而持续降低成本的方法，而朴素预测等传统方法的性能并未随数据规模扩大而显著改善。图 \ref{fig:paper_fig5} 展示了随着数据量增加，机器学习模型与 SAA 方法组合的成本优势逐渐扩大的趋势，呈现出显著的规模收益。

\begin{figure}[htbp]
    \centering
    \IfFileExists{figure5.png}{\includegraphics[width=0.8\textwidth]{figure5.png}}{\fbox{Figure 5 图缺失}}
    \caption{原文 Figure 5：不同样本量大小对库存成本的影响 ($SL=0.7$)}
    \label{fig:paper_fig5}
\end{figure}

\subsection{小组复现结果}
为了验证原论文提出的数据驱动框架在不同数据集上的泛化能力与有效性，本研究采用 \textbf{Kaggle "French Bakery Daily Sales"} 数据集，筛选销量排名前 10 的核心产品（样本量 $N \approx 6300$），对需求估计、库存优化及集成优化三个层级进行了系统性的复现与实证分析。

\subsubsection{Level 1: 需求预测与特征工程}
在需求估计层面，本研究构建了包含短期与周期性滞后项（$Lag\_1, Lag\_7$）及日历特征（\texttt{weekday}, \texttt{month}）的高维特征空间，并分别训练了作为基准的线性回归模型与作为核心研究对象的随机森林模型。

实证结果如表 \ref{tab:level1_perf} 所示，机器学习模型展现出显著优越的拟合优度。具体而言，Random Forest 模型的 $R^2$ Score 达到 \textbf{92.89\%}，显著高于线性基准模型的 90.10\%；同时，其均方根误差从 27.54 降至 23.35，相对改善幅度达 \textbf{15.2\%}。

这一结果表明，简单的线性模型难以充分挖掘数据中的特征价值。而通过引入非线性模型（随机森林），能够有效捕捉面包销售数据中存在的“周度季节性”与“短期自相关”之间的复杂非线性交互关系，从而大幅降低预测残差，为后续的库存决策提供更精准的均值估计。

\begin{table}[htbp]
    \centering
    \caption{Level 1 需求预测模型性能对比}
    \label{tab:level1_perf}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Model} & \textbf{RMSE} & \textbf{MAE} & \textbf{$R^2$ Score} \\
        \midrule
        Linear Regression & 27.54 & 14.82 & 90.10\% \\
        \textbf{Random Forest} & \textbf{23.35} & \textbf{12.71} & \textbf{92.89\%} \\
        \midrule
        \textit{Improvement} & \textit{-15.2\%} & \textit{-14.2\%} & \textit{+2.79 \%} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Level 2: 统计检验与库存决策优化}
在库存决策阶段，本研究首先对 Random Forest 模型的预测残差进行了统计诊断，随后对比了参数化与非参数化方法的成本表现。

\textbf{1. 残差分布诊断}：
Shapiro-Wilk 正态性检验结果显示，p-value 远小于显著性水平 0.05 ($p = 1.94 \times 10^{-70}$)，从而在统计上以极高的置信度\textbf{拒绝了残差服从正态分布的原假设}。这一显著的非正态特征表明传统参数模型存在模型误设风险，为采用基于样本均值逼近的非参数方法提供了坚实的统计学依据。

\textbf{2. 决策敏感性与尾部效应}：
我们测试了不同目标服务水平下各方法的平均日成本，具体结果如表 \ref{tab:cost_comparison} 所示。通过对比分析，我们观察到显著的\textbf{“尾部效应”}：

在中低服务水平（$SL \le 0.7$）下，正态参数化方法表现稳健，成本与 SAA 方法持平甚至略优，这符合中心极限定理在分布中心区域的适用性。然而，随着服务水平的提升（$SL \ge 0.8$），数据驱动的 SAA 方法展现出显著优势；特别是在 $SL=0.95$ 的极端分位数下，SAA 的平均成本较正态假设降低了约 \textbf{10\%}。该结果证实，正态假设倾向于低估极端需求的概率（即忽视了“肥尾”现象），而 SAA 方法在处理高服务水平要求的库存决策时具有更强的鲁棒性。

\begin{table}[htbp]
    \centering
    \caption{不同服务水平下的平均日成本对比}
    \label{tab:cost_comparison}
    \begin{tabular}{c|cc|c}
        \toprule
        \textbf{Service Level} & \multicolumn{2}{c|}{\textbf{Level 2}} & \textbf{Level 3} \\
        \textbf{目标} & 正态 & \textbf{SAA} & 分位数回归 \\
        \midrule
        0.50 & \textbf{9.52} & 9.55 & 10.56 \\
        0.70 & \textbf{9.32} & 9.34 & 9.55 \\
        0.80 & 9.65 & \textbf{9.27} & 9.81 \\
        0.90 & 10.43 & \textbf{9.45} & 11.95 \\
        0.95 & 11.24 & \textbf{10.15} & 13.19 \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{3. 决策可视化解读}：
图 \ref{fig:level2_viz} 直观展示了某一产品在测试集期间的决策细节。图中绿色阴影区域表示超储带来的浪费成本，红色阴影区域表示缺货带来的机会成本。可以看出，SAA 方法计算出的订货量（绿线）并非对预测均值（蓝线）的简单线性平移，而是根据局部残差分布特征进行动态调整，从而在需求波峰处有效控制了缺货风险（红色区域面积）。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{../output/inventory_result.png}
    \caption{Level 2 决策可视化：真实需求、ML 预测值与基于 SAA 的最优订货量}
    \label{fig:level2_viz}
\end{figure}

\subsubsection{Level 3: 基于分位数回归的集成优化}
作为本研究的进阶探究，我们复现了基于\textbf{分位数回归}的端到端决策模型，旨在验证“集成估计与优化”策略的有效性。

\textbf{1. 模型构建与超参数调优}：
具体实施中，本研究采用 \texttt{GradientBoostingRegressor} 作为基学习器，将损失函数设定为分位数损失，直接针对特定服务水平 $\alpha = \frac{c_u}{c_u + c_o}$ 优化最优订货量 $q(x)$。为了防止过拟合，我们采用了 3 折时间序列交叉验证，在包含 \texttt{n\_estimators}、\texttt{max\_depth} 及 \texttt{learning\_rate} 的参数网格中进行搜索。

表 \ref{tab:level3_tuning} 展示了不同服务水平下的最优模型配置。可以看出，随着目标分位数的提高（即服务水平要求变严），模型倾向于选择更复杂的参数组合（如更高的 \texttt{n\_estimators}），以捕捉尾部极端值的非线性模式。

\begin{table}[htbp]
    \centering
    \caption{Level 3 集成优化模型最优超参数配置}
    \label{tab:level3_tuning}
    \small
    \begin{tabular}{ccc}
        \toprule
        \textbf{Target SL} & \textbf{Test Cost} & \textbf{Best Parameters (n\_estimators, max\_depth, lr)} \\
        \midrule
        0.50 & 10.56 & (400, 2, 0.05) \\
        0.70 & \textbf{9.55} & (200, 3, 0.05) \\
        0.80 & 9.81 & (100, 3, 0.10) \\
        0.90 & 11.95 & (100, 2, 0.10) \\
        0.95 & 13.19 & (400, 4, 0.03) \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{2. 综合成本分析与局限性讨论}：
图 \ref{fig:cost_curve} 汇总了 Normal、SAA 及 Integrated 三种方法在多服务水平下的成本演变趋势。总体而言，随着目标服务水平的提升，由于缺货惩罚权重的增加，所有模型的预期总成本均呈现上升态势。

在具体方法对比中，Integrated 方法（绿线）在 $SL=0.70$ 处取得了全场最低的平均日成本（9.55），展现了端到端学习策略在特定区间的优化潜力；然而，当进入 $SL \ge 0.90$ 的高服务水平区间时，集成方法并未表现出优于 SAA 方法（橙线）的显著优势，部分指标甚至略有逊色。这一现象与原论文的实证结论高度一致，主要归因于端到端模型试图在有限样本（本研究约 6300 条）下直接学习输入特征与极端分位数（如 95\% 分位点）之间的复杂非线性映射，其对数据规模的高敏感性导致了在数据稀疏区域的泛化能力不如结构更为简约的 SAA 方法稳定。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.70\textwidth]{../output/cost_curve.png}
    \caption{多服务水平下的平均成本对比曲线}
    \label{fig:cost_curve}
\end{figure}

% 第四部分：理解与思考
\section{Understanding, Comments and Thinking}

\subsection{统计学视角的洞察}
\begin{itemize}
    \item \textbf{Prediction $\neq$ Decision}：统计上的“高预测精度”（低 MSE）并不完全等同于商业上的“低成本”。针对特定损失函数进行优化是应用统计的高级方向。
    \item \textbf{非参数的胜利}：本研究再次印证了在“大数据”时代，基于经验分布的 SAA 方法往往比强依赖假设的参数模型更安全、更有效。
\end{itemize}

\subsection{局限与改进}
\begin{itemize}
    \item \textbf{删失数据}：当前的复现假设 $Sales \approx Demand$，忽略了缺货导致的截断。未来可引入 \textbf{Tobit 模型} 或 Survival Analysis 中的 Kaplan-Meier 估计来还原真实需求。
    \item \textbf{算法扩展}：考虑到实际数据量可能有限，未来可对比 \textbf{Random Forest} 或 \textbf{XGBoost}，这些树模型通常在表格数据上比简单的 ANN 表现更稳健。
\end{itemize}

\end{document}
